\documentclass[12pt]{article}
\usepackage{bibentry}
\usepackage{caption}
\usepackage{float}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage{tabto}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{tabularx}




\lstset{
    frame=single,
    breaklines=true,
    postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\color{red}\hookrightarrow\space}}
}

\graphicspath{{images/}}

\author{Aldar Saranov}
\date{\today}
\title{Development of an automatically configurable ant colony optimization framework. State of the art.}

\newmdenv[
  backgroundcolor=gray!20,
  frametitle=Definition,
  skipabove=\topsep,
  skipbelow=\topsep,
]{definition}

\newmdenv[
  backgroundcolor=white!20,
  frametitle=Algorithm,
  skipabove=\topsep,
  skipbelow=\topsep,
]{algorithm}

\newcommand{\dd}[1]{\mathrm{d}#1}


%--------------------------------------------------------------------------------



\begin{document}

\maketitle 
\newpage

\tableofcontents
\newpage

\begin{abstract}
Some animal species show an extreme degree of social organization. Such species (e.g. ants) have pheromone production and detection body parts and therefore seize an ability to communicate between each other in an indirect way. This concept has inspired the development of algorithms, which are based on the social behavior of the ant colonies called ant colony optimization algorithms. These algorithms allow to solve NP-hard problems in a very efficient manner. These algorithms are considered to be metaheuristics. The development of an ACO framework is the next step of formalizing this area. Such a framework can then be used as a tool to help resolving various optimization problems. This report gives a brief overview of the current state of the ACO research area, existing framework description and some tools which can be used for the automatic configuration of the framework.
\end{abstract}




\section{Introduction}

REDO introduction!!!

In this report we display the current research state of the Ant Colony Optimization frameworks that solve optimization problems and their configuration. To do that we split the report into several sections which will represent different practical points of the ACO application. \\
In the section 2 we introduce the basic notions of the Combinatorial Optimization Problems. These problems are described by means of two particular NP-hard problems - the  Traveling Salesman Problem and the Quadratic Assignment Problem. For them, we define the problem formulations as well as the objective functions. \\
In the section 3 we provide a description of the Ant Colony Optimization. One describes the ACO in terms of constructive heuristics. Besides, we introduce the notion of pheromone trails and explain how they affect the solution construction. In addition to the general ACO resolution algorithm, we conduct an overview of various algorithm extensions which are meant to increase its performance. Two types of pheromone update are presented - global and local. Different Ant Systems are briefly described. \\
In the section 4 we describe the application of ACO for different problem classes. Those are Continuous Optimization Problems, Multi-objective Problems, Dynamic Problems and Stochastic Problems. \\
The existing optimization frameworks are described in the section 5 where we mainly focus on single-objective optimization problem and ad hoc ACOTSPQAP framework. However, several other frameworks with different purposes and ideas are mentioned. \\
Automatic configuration process which is applied "above" the developed ACO algorithms is explained in the section 6. The top-level outline of this process is shown as well as the I-RACE implementation which is already developed and tested. \\
In section 7 we list the configurations that were rendered by the configuration process on a test set for both TSP and QAP problems. \\
The section 8 concludes the report and proposes further possible contributions into the area.

\input{section-2}
\input{section-3}

\section{Applications of ACO to other problem types}
Initially ACO algorithms were meant to solve single-objective combinatorial optimization problems. However, ACO algorithms can be applied to other problem types.


\textbf{Continuous Optimization Problems}. The simplest way to solve COPs by means of ACO algorithms is to approximate the problem to its discrete analogue, however, it cannot be applied to certain problems. Some adaptations are carried out by Socha and Dorigo \cite{aco_continuous}. Another model was presented by Liao\cite{aco_incremental}.

\textbf{Multi-objective problems} are problems that have several objective functions which sometimes have a deterministic preference model or demand the Pareto set as the solution. In practice, such problems normally do not have a preference of one Pareto-optimal solutions over others. For example, one of such problems which has been solved is bi-objective Traveling Salesman Problem (bTSP). This problem is identical to the original TSP, except that it has two length markups for each edge, and each of two objective functions corresponds to tour length is estimated by one of these length markups.

So far, various multi-objective ACO algorithms have been developed. Several ACO algorithms for resolving such problems were reviewed in the paper of L{\'o}pez-Ib{\'a}{\~n}ez and Thomas St{\"u}tzle \cite{moaco}. Different MOACO algorithms implement different design choices and, therefore, have different algorithmic components. This was the reason to implement a unified flexible framework. The developed MOACO framework encompasses many MOACO algorithms. This framework allows either to instantiate MOACO algorithms based on the existing ones, or to combine algorithmic components from different MOACO algorithms to produce new ones.

For solution component choice the possible options are \emph{single/multiple pheromone trails and single/multiple heuristic information}. Since multiple pheromone matrices need to be aggregated into a single one, it is necessary to choose the aggregation rule. That can be \emph{weighted sum/weighted product/random/next-weight aggregation}. As for selecting a solution for pheromone information update one can choose \emph{non-dominated solutions/ best-of-objective/best-of-objective-per-weight}.

Many MOACO algorithms use the idea of multiple colonies with different application of those. A colony is a group within the total ant population. Each such group is associated to its own pheromone information. Thus, in bi-objective case each colony has two pheromone matrices. The following algorithmic components define cooperation behavior of colonies. \emph{MultiColonyWeights} defines how the colonies share the weights that are defined at the aggregation step. \emph{MultiColonyUpdate} defines the notion of solution archive where the solutions from colonies are submitted. After this they are redistributed back to the colonies for pheromone information update. Thus, the colonies exchange the solutions between each other.

As it was said, these algorithmic components are combined in order to obtain new MOACO algorithms, and therefore, it is possible to perform an automatic configuration of these algorithms.


\textbf{Dynamic problems} are problems that have some information (such as data or objectives) revealed in time. Such problems are usually encountered in network routing. In problems like dynamic TSP and dynamic vehicle routing problem cities appear and disappear during the solution, as well as distances between them. These problems are resolved in a strongly different manner - ants act asynchronously and no global pheromones are updated, instead specific update mechanisms are held. An overview of ACO algorithms in application to dynamic optimization problems was done by Alba Leguizam{\'o}n in \cite{dynamic_overview}.

\textbf{Stochastic problems} deal with information that is not deterministic. Such problems mean that instead of deterministic values of the problem data and objectives, we have their probability distribution. In practice such problems are caused by uncertainty or noise affecting the problem information. The first stochastic problem to deal with was probabilistic TSP (pTSP), where for each city there is a given probability that it is required to visit. The first algorithm was proposed by Bianchi in \cite{bianchi_stochastic_tsp} with further development by Guntsch and Branke in \cite{guntsch_stochastic}.






\section{Existing optimization frameworks}

\subsection{ACOTSPQAP}

ACOTSPQAP is a unified framework that was developed by researchers of the IRIDIA group, which is publicly available at http://iridia.ulb.ac.be/aco-tsp-qap/. It was developed with aim to provide generality of algorithmic components of ACO algorithms. It separates the general structures of ACO metaheuristics from the problem-specific domain. All standard parameters can be specified ($\alpha, \beta, \rho, m, \epsilon, etc.$) plus one can set the specific parameters ($t_{max}, t_{min}, res_{it}$ - number of iterations since last found rb-solution, $res_{bf}$ - branching factor, $res_{dist}$ - distance between global-best and iteration-worst ants, $q_0$). All these parameters are to be tuned by an external configuration software.

Algorithmic frameworks can be classified as one of these two (although their distinction is ambiguous in particular cases):
\begin{itemize}
\item Top-down - develop a fixed template-based algorithm. It is based on strictly structured algorithm which allows some parametric configuration of some of its details with minor behavior modifications.
\item Bottom-up - algorithm is build of flexible components with some rule restrictions. Often involves application of genetic programming and evolution ideas.
\end{itemize}

ACOTSPQAP can be classified as the first one, since its stages (solution generation, local search, pheromone trail update) are concretely defined and its parameters are strongly determined.

\subsection{Other frameworks}

The \textbf{MOACO} framework was briefly described in the section 4. Besides there are some other optimization frameworks which have different features.

Another remarkable framework is \textbf{SATenstein}. It is based on solving satisfiability problem (SAT) of a boolean formula. SAT problem is considered important because other NP-complete problems can be encoded as instances of SAT problem. Various Stochastic Local Search (SLS) algorithms have been developed for solving SAT problems. The SATenstein can be configured to instantiate a broad range of existing high-performance SLS-based solvers \cite{satenstein}. The general form of SLS algorithm is made of five blocks. First block performs search diversification. Blocks from the second to the fourth perform a variable flip with instantiating $G^2$WSAT-derived, WalkSAT-based or dynamic local search algorithm respectively. The fifth block performs updates to the promising variable list, tabu attributes, clause penalties or dynamically adapted algorithm parameters. Thus, a high-performing SLS algorithm can be assembled of such algorithmic blocks in SATenstein. A generic algorithmic configuration tool was applied to SATenstein for finding best algorithm instantiations for predefined sets, which is described in the mentioned paper.

\textbf{Hybrid Stochastic Local Search} (SLS) algorithms, as in the previously mentioned frameworks, are composed of the separate algorithmic components. These algorithms rely on the manipulating a single solution called \emph{current solution}. The neighborhood of the current solution will be explored during the algorithm run \cite{hsls}. The first phase of the algorithm is the local search for the initial solution. Then the algorithm iterations start. One iteration consists from \emph{perturbation, local search} and \emph{acceptanceCriterion}. Perturbation is a transformation of the input solution. Perturbation may be implemented as one simple move in neighborhood space, but it may also be composed of $k$ applications of such moves. \emph{Local search} can range from a simple iterative improvement over short runs of an SA algorithm to a full-fledged iterated local search. \emph{Acceptance criterion} returns either the initial solution or the obtained one, according to some condition. The simplest criterion is \emph{improveAccept} accepts the solution with better quality. Other acceptance criteria allow worse solutions to be accepted in order to increase the exploration of the search space. For instance \emph{probAccept} accepts a worsening solution with probability $p \in [0;1]$. These iterations are repeated until a defined termination criterion is fulfilled. As a result, such metaheuristic algorithms are among the most effective non-exact algorithms for tackling hard combinatorial optimization problems.


\section{Automatic configuration in IRACE}

Automatic configuration is a process that optimizes the performance of a certain algorithm as a goal function based on input parameters of the algorithm. The general parameter types are:
 
\begin{itemize}
\item \textbf{categorical} parameters - represent discrete values without any implicit order or distance measure between its possible values. Define the choice of constructive procedure, choice of branching strategies (i. e. algorithmic blocs) and so on. An example of such parameter in ACO algorithms is recombination operators in EAS.
\item \textbf{ordinal} parameters - are also assigned to finite discrete values, but they have implicit value order (such as \emph{low, middle, high}). Define lower bounds, neighborhoods.
\item \textbf{numerical} parameters - define integer or real values/constants such as weighting factors, population sizes, temperature. They can be optional according to different categorical parameter values.
\end{itemize}

Some of the parameters may subordinate to the other ones. This means that their values only make sense if the parameters they subordinate to are assigned to certain values. This can be expressed as scalar value constraints (e.g $a < b$) or dependency on concrete values of some categorical or ordinal parameter.

\begin{figure}[H]
  \centering
    \includegraphics[scale=0.7]{configuration-top-level.png}
  \caption{Automatic configuration scheme}
  \label{fig:autoconf}
\end{figure}

Figure \ref{fig:autoconf} shows software composition of the configuration software and software to configure. Configuration script has parameter metadata in its disposal. Based on them, the configuration software runs the software to configure with candidate configurations according to some algorithm. After the configuration process finishes, the configuration software renders the best configuration obtained. In the most general software case there are two measures of the performance - solution quality (to maximize) and computation time (to minimize).

There are two application modes:
\begin{itemize}
\item Offline tuning - introduces a learning stage on training instances before learning on the real-world set.
\item Online tuning - tunes the parameters while solving the real-world instance set.
\end{itemize}

A widely used configuration algorithmic family is racing algorithms. The simplified algorithm is shown in \ref{lst:racing} and an illustration is in \ref{fig:irace}.


\begin{minipage}[c, breaklines=true]{0.95\textwidth}
\begin{lstlisting}[caption={General racing pseudo-code}, label={lst:racing}]
procedure racing
start with an initial candidate set Theta
repeat iterations I
	process an instance stream
	evaluate the candidates sequentially
	remove inferior candidates
until winner is selected or exit condition fulfilled
end
\end{lstlisting}
\end{minipage}

\begin{figure}[H]
  \centering
    \includegraphics[scale=1.2]{irace.jpg}
  \caption{I-RACE execution illustration}
  \label{fig:irace}
\end{figure}


I-RACE (iterated race) configuration implementation was developed and described in \cite{iraceaac}. It was implemented in R with taking into account the parallel programming techniques and initial candidate set-up. The feature of the IRACE is based on iterated generation of new configurations and removing of solutions with lower quality for further evaluating on the problem instances.

In order to tune the configurations that are sampled, IRACE algorithms uses independent sampling distribution for each of the parameters. For numeric values those are normal distributions and discretely-defined for the rest. The configuration biasing procedure is based on modifying the sampling distributions.

Iterated racing is an automatic configuration implementation that consists from three steps:

\begin{itemize}
\item Sampling new configurations according to a particular distribution.
\item Selecting the best configurations from the newly sampled ones by means of racing.
\item Updating the sampling distribution in order to bias the sampling towards the best configurations.
\end{itemize}

After new configurations are sampled comes the selection stage. At configuration selection stage, IRACE runs each of the configurations on a single problem instance from the predefined instance set. After each racing iteration the worst configurations are discarded. Then the rest of the configurations update parameter sampling distributions. The racing stops when the number of the survived configurations becomes small enough.  

Some IRACE extensions can be applied. \textbf{Initial configurations} can be set before the run of the IRACE. \textbf{Soft-restart} is used for preventing premature convergence. Such convergence may suppresses configuration diversity and, therefore good configurations may be lost. This restart is triggered if the value of an ad hoc configuration distance function is lower than a certain margin. Then reinitialization is applied to the elite configurations.


\section{Research state}

The higher-mentioned ACOTSP framework accompanied by IRACE R script have already produced results for the TSP and the QAP problems. The results are described in the following two subsections. General conclusion during this research is that solutions obtained by the optimal configurations are better than those obtained by the default configurations. The comparison was carried out by measuring the deviation from the optimal solution for each instance.

\subsection{Finding a better ACO configuration for the TSP}

The optimal configuration is mentioned in the table \ref{table:table-tsp}, where it was computed for different algorithms. Various instances of different sizes were generated for the configuration process.

\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}
{
\begin{tabular}{|r|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline 
    algo & $m$ & $\alpha$ & $\beta$ & $\rho$ & $q_0$ & $\epsilon$ & $cl$ & $nnls$ & $ph-limits$ & $slen$ & $restart$ & $res_{it}$\\ \hline
    ACS & 28 & 3.07 & 5.09 & 0.32 & 0.53 & 0.21 & 22 & 9 & - & - & branch-factor ($res_{bf} = 1.74$) & 212\\ \hline
	MMAS & 40 & 0.94 & 4.11 & 0.72 & 0.14 & - & 18 & 12 & yes & 191 & branch-factor ($res_{bf} = 1.91$) & 367\\ \hline
\end{tabular}
}
\caption{Optimal configuration for the TSP problem.}
\label{table:table-tsp} 
\end{table} 

With local search as 3-opt + dlb-bits.

\subsection{Finding a better ACO configuration for the QAP}

Problem instances were implemented in two forms - as RR or RS. In RR the distance matrix is computed as paired euclidean distances of points distributed on a square of length 300 in uniform way. The flow matrix is generated as a matrix of uniform random values within certain range. The RS distance matrix is generated in the same way, but the flow matrix adheres to real-world flow values.

100 instances were considered where half of them was used for training and the another half for testing. The best found configuration are shown in the table \ref{table:table-qap}.

\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}
{
\begin{tabular}{|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline 
    & algo & $m$ & $\alpha$ & $\rho$ & $q_0$ & $dlb-bits$ & $ph-limits$ & $slen$ & $restart$ & $res_{it}$\\ \hline
    RR & MMAS & 6 & 0.324 & 0.29 & 0.062 & yes & no & 153 & distance ($res_{bf} = 0.051$) & 22\\ \hline
	RS & MMAS & 4 & 0.164 & 0.342 & 0.284 & yes & no & 170 & branch-factor ($res_{bf} = 1.822$) & 40\\ \hline
\end{tabular}
}
\caption{Optimal configuration for the TSP problem.}
\label{table:table-qap} 
\end{table} 

With local search as 2-best-opt.

\section{Conclusions}

Vast research work has been already conducted in terms of ACO algorithms. Many types of ACO algorithms and their extensions were developed and tested. However there are still many COPs untouched. In addition, various technical details can be added in order to improve resolution performance or the development experience. 

Various ways of further area research can be proposed. The possible way is to implement resolution algorithms for new NP-hard problems within ACO framework. Such practical problems as Vehicle Routing Problem, Subset Sum Problem or Knapsack Problem.

From technical point of view we can propose implementing a new framework using object-oriented paradigm which will ensure high modularity and modification-proneness. Another option is to implement the ACO algorithm stages as parallel algorithms (stages like solution generation or local search). 




\begin{thebibliography}{1}

\bibitem{aco_overview} Manuel L{\'o}pez-Ib{\'a}{\~n}ez and Thomas St{\"u}tzle {\em Ant Colony Optimization: A Component-Wise Overview} 2015: IRIDIA - Technical Report Series.

\bibitem{comb_opt} Papadimitriou CH, Steiglitz K {\em Ant Colony Optimization: A Component-Wise Overview} 1982: IRIDIA - Prentice Hall, Englewood Cliffs, NJ.

\bibitem{maniezzo} Maniezzo V {\em Exact and approximate nondeterministic tree-search procedures for the quadratic assignment problem} 1999: INFORMS Journal on Computing.

\bibitem{dorigo} Dorigo M, Gambardella LM {\em Ant Colony System: A cooperative learning
approach to the traveling salesman problem} 1997: IEEE Transactions on Evolutionary
Computation.

\bibitem{lookahead} Michel R, Middendorf M {\em An island model based Ant System with
lookahead for the shortest supersequence problem} 1998: Nature, PPSN V, Lecture Notes in Computer Science.

\bibitem{lookahead2} Caroline Gagn{\'e}, Marc Gravel, Wilson L. Pirce {\em  A look-ahead addition to the ant colony optimization metaheuristic and its application to an industrial scheduling} 2001: D{\'e}partement d'Informatique et de Math{\'e}matique, Universtit{\'e} du Qu{\'e}bec {\'a} Chicoutimi.

\bibitem{candidate_list} Dorigo M, Di Caro GA {\em The Ant Colony Optimization meta-heuristic} 1999: New Ideas in Optimization, McGraw Hill, London, UK.

\bibitem{hash_table} Alba E, Chicano F {\em ACOhg: dealing with huge graphs} 2007: Proceedings of the Genetic and Evolutionary Computation Conference.

\bibitem{iterated_greedy} Ruiz R, Thomas St{\"u}tzle {\em A simple and effective iterated greedy algorithm for the permutation flowshop scheduling problem} 2007: European Journal of Operational Research.

\bibitem{iterated_ants} Wolfram Wiesemann and Thomas St{\"u}tzle {\em Iterated Ants: An Experimental Study for the Quadratic Assignment Problem} 2006: Fachbereich Wirtschaftswissenschaften.

\bibitem{cunning_ants} Shigeyoshi Tsutsui {\em cAS: Ant Colony Optimization with Cunning
Ants} 2006: Hannan University, Matsubara Osaka.

\bibitem{mmas} Thomas St{\"u}tzle and Hoos HH {\em MAX–MIN Ant System} 2000: Future Generation Computer Systems.

\bibitem{ras} Bullnheimer B, Hartl R, Strauss C {\em A new rank-based version of the
Ant System} 1999: Central European Journal for Operations Research and Economics.

\bibitem{eas} Dorigo M {\em Optimization, learning and natural algorithms} 1992: Dipartimento di Elettronica, Politecnico di Milano, Italy.

\bibitem{bwas} Cordon O, de Viana IF, Herrera F, Moreno L {\em A new ACO model
integrating evolutionary computation concepts: The best-worst ant system} 2000: Second International Workshop on Ant Algorithms.

\bibitem{coop_tsp} Dorigo M, Gambardella LM {\em Ant Colony System: A cooperative learning approach to the traveling salesman problem.} 1997: IEEE Transactions on Evolutionary
Computation.

\bibitem{iraceaac} Manuel L{\'o}pez-Ib{\'a}{\~n}ez  and  J{\'e}r{\'e}mie Dubois-Lacoste  and Leslie {P{\'e}rez C{\'a}ceres}  and  Thomas St{\"u}tzle  and  Mauro Birattari {\em Iterated Racing for Automatic Algorithm Configuration} 2013: IRIDIA - Technical Report Series.

\bibitem{aco_continuous} Socha K, Dorigo M {\em Iterated Racing for Automatic Algorithm Configuration} 2008: European Journal of Operational Research.
  
\bibitem{aco_incremental} Liao T, Montes de Oca MA, Aydin D, St{\"u}tzle T, Dorigo M {\em An incremental ant colony algorithm with local search for continuous optimization} 2011: Proceedings of the Genetic and Evolutionary
Computation Conference.  
  
\bibitem{moaco} L{\'o}pez-Ib{\'a}{\~n}ez M, St{\"u}tzle T {\em The automatic design of multi-objective ant colony optimization algorithms} 2012: IEEE Transactions on Evolutionary Computation.    
  
\bibitem{moba} Xin-She Yang {\em Bat Algorithm for Multi-objective Optimisation} 2011: Department of Engineering, University of Cambridge.  

\bibitem{dynamic_overview} Leguizam{\'o}n G, Alba E (2013) Ant colony based algorithms for dynamic optimization problems. In: Alba E, Nakib A, Siarry P (eds) Metaheuristics for Dynamic Optimization, Studies in Computational Intelligence, vol 433, Springer, Berlin/Heidelberg, pp 189–210
 
\bibitem{bianchi_stochastic_tsp} Bianchi L, Gambardella LM, Dorigo M (2002) An ant colony optimization approach to the probabilistic traveling salesman problem. In: Merelo JJ, et al (eds) Parallel Problem Solving from Nature, PPSN VII, Springer, Heidelberg, Germany, Lecture Notes in Computer Science, vol 2439, pp 883–892

\bibitem{guntsch_stochastic} Guntsch M, Branke J (2003) New ideas for applying ant colony optimization to the probabilistic tsp. In: Cagnoni S, et al (eds) Applications of Evolutionary Computing, Proceedings of EvoWorkshops 2003, Springer, Heidelberg, Germany, Lecture Notes in Computer Science, vol 2611, pp 165–175

\bibitem{hsls} Marie-El´eonore Marmion, Franco Mascia,
Manuel L{\'o}pez-Ib{\'a}{\~n}ez, and Thomas St{\"u}tzle (2013) IRIDIA, CoDE, Universit{\'e} Libre de Bruxelles (ULB), Brussels, Belgium, pp 144-158

\bibitem{satenstein} . R. KhudaBukhsh, L. Xu, H. H. Hoos, K. Leyton-Brown (2009) SATenstein: Automatically Building Local Search SAT Solvers From Components, Twenty-First International Joint Conference on Artificial Intelligence (IJCAI-09)

 
\bibitem{external_memory} Dorigo, Marco
and Birattari, Mauro
and Blum, Christian
and Gambardella, Luca Maria
and Mondada, Francesco
and St{\"u}tzle, Thomas {\em IAn External Memory Implementation in Ant Colony Optimization} 2004: Springer Berlin Heidelberg - Proceedings.

\end{thebibliography}

 
\end{document} 
