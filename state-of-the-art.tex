\documentclass[12pt]{article}
\usepackage{bibentry}
\usepackage{caption}
\usepackage{float}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage{tabto}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{tabularx}




\lstset{
    frame=single,
    breaklines=true,
    postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\color{red}\hookrightarrow\space}}
}

\graphicspath{{images/}}

\author{Aldar Saranov}
\date{\today}
\title{Development of an automatically configurable ant colony optimization framework. State of the art.}

\newmdenv[
  backgroundcolor=gray!20,
  frametitle=Definition,
  skipabove=\topsep,
  skipbelow=\topsep,
]{definition}

\newmdenv[
  backgroundcolor=white!20,
  frametitle=Algorithm,
  skipabove=\topsep,
  skipbelow=\topsep,
]{algorithm}

\newcommand{\dd}[1]{\mathrm{d}#1}


%--------------------------------------------------------------------------------



\begin{document}

\maketitle 
\newpage

\tableofcontents
\newpage

\begin{abstract}
Some species show an extreme degree of social organization. Such species (e.g. ants) have pheromone production and detection body parts and therefore seize an ability to communicate between each other in an indirect way. This concept has inspired the development of algorithms, which are based on the social behavior of the ant colonies called ant colony optimization algorithms. These algorithms allow to solve NP-hard problems in a very efficient manner. These algorithms are considered to be metaheuristics. The development of an ACO framework is the next step of formalizing this area. Such a framework can then be used as a tool to help resolving various optimization problems. This report gives a brief overview of the current state of the ACO research area, existing framework description and some tools which can be used for the automatic configuration of the framework.
\end{abstract}




\section{Introduction}



Metaheuristic algorithms are widely used for solving such difficult problems as NP-hard problems, since the exact solution of such problems often takes unreasonable computational time in practice. One family of such algorithms is the Ant Colony Optimization algorithms. These algorithms comprise a various set of options, that affect the final performance of the algorithm. Thus, it is a logical decision to develop a unified framework which summarizes ACO algorithmic components for later assembly of ACO algorithms. After developing such a framework, the next step is to create a tuning tool that will observe the configurations space of ACO algorithms and select the best ones, in order to improve the quality of obtained solutions.
In this report, we display the current research state of the Ant Colony Optimization frameworks that solve optimization problems and their configuration. To do that we split the report into several sections which will represent different practical points of the ACO application. \\
In the section 2, we introduce the basic notions of  Combinatorial Optimization Problems and will introduce the Traveling Salesman Problem and the Quadratic Assignment Problem as examples of NP-hard problems to solve. In the section 3, we provide a description of Ant Colony Optimization in terms of constructive heuristics with introduction into the main components and choices of this metaheuristic. In the section 4, we describe the application of ACO to different problem classes such as continuous optimization problems, multi-objective problems, dynamic problems and stochastic problems.
The existing optimization frameworks are described in section 5, where we describe the ACOTSPQAP framework and some additional frameworks with other purposes.
Automatic configuration process, which is applied "above" the developed ACO algorithms, is explained in the section 6.
In section 7, we list the configurations that were rendered by the configuration process on a test set for both TSP and QAP problems.
Section 8 concludes the report and proposes further possible contributions into the area.

\input{section-2}
\input{section-3}

\section{Applications of ACO to other problem types}
Initially ACO algorithms were meant to solve single-objective combinatorial optimization problems. However, ACO algorithms can be applied to other problem types.


\textbf{COPs}. The simplest way to solve COPs by means of ACO algorithms is to approximate the problem to its discrete analogue, however, it cannot be applied to certain problems. Some adaptations are carried out by Socha and Dorigo \cite{aco_continuous}. Another model was presented by Liao\cite{aco_incremental}.

\textbf{Multi-objective problems} are problems that have several objective functions, which sometimes have a deterministic preference model or demand the Pareto set as the solution. In practice, such problems normally do not have a preference of one Pareto-optimal solutions over others. For example, one such problem, which has been solved, is bi-objective Traveling Salesman Problem (bTSP). This problem is identical to the original TSP, except that it has two length markups for each edge, and each of two objective functions corresponds to tour length is estimated by one of these length markups.

So far, various multi-objective ACO algorithms have been developed. Several ACO algorithms for resolving such problems were reviewed in the paper of L{\'o}pez-Ib{\'a}{\~n}ez and Thomas St{\"u}tzle \cite{moaco}. Different MOACO algorithms implement different design choices and, therefore, have different algorithmic components. This was the reason to implement a unified flexible framework. The developed MOACO framework encompasses many MOACO algorithms. This framework allows either to instantiate MOACO algorithms based on the existing ones, or to combine algorithmic components from different MOACO algorithms to produce new ones.

For solution component choice the possible options are \emph{single/multiple pheromone trails and single/multiple heuristic information}. Since multiple pheromone matrices need to be aggregated into a single one, it is necessary to choose the aggregation rule. That can be \emph{weighted sum/weighted product/random/next-weight aggregation}. As for selecting a solution for pheromone information update one can choose \emph{non-dominated solutions/ best-of-objective/best-of-objective-per-weight}.

Many MOACO algorithms use the idea of multiple colonies with different application of those. A colony is a group within the total ant population. Each such group is associated to its own pheromone information. Thus, in bi-objective case each colony has two pheromone matrices. The following algorithmic components define cooperation behavior of colonies. \emph{MultiColonyWeights} defines how the colonies share the weights that are defined at the aggregation step. \emph{MultiColonyUpdate} defines the notion of solution archive where the solutions from colonies are submitted. After this they are redistributed back to the colonies for pheromone information update. Thus, the colonies exchange the solutions between each other.

As it was said, these algorithmic components are combined in order to obtain new MOACO algorithms, and therefore, it is possible to perform an automatic configuration of these algorithms.


\textbf{Dynamic problems} are problems that have some information (such as data or objectives) revealed in time. Such problems are usually encountered in network routing. In problems like dynamic TSP and dynamic vehicle routing problem cities appear and disappear during the solution, as well as distances between them. These problems are resolved in a strongly different manner - ants act asynchronously and no global pheromones are updated, instead specific update mechanisms are held. An overview of ACO algorithms in application to dynamic optimization problems was done by Alba Leguizam{\'o}n in \cite{dynamic_overview}.

\textbf{Stochastic problems} deal with information that is not deterministic. Such problems mean that instead of deterministic values of the problem data and objectives, we have their probability distribution. In practice such problems are caused by uncertainty or noise affecting the problem information. The first stochastic problem to deal with was probabilistic TSP (pTSP), where for each city there is a given probability that it is required to visit. The first algorithm was proposed by Bianchi in \cite{bianchi_stochastic_tsp} with further development by Guntsch and Branke in \cite{guntsch_stochastic}.






\section{Existing optimization frameworks}

\subsection{ACOTSPQAP}

ACOTSPQAP is a unified framework that was developed by researchers of the IRIDIA group, it is publicly available at http://iridia.ulb.ac.be/aco-tsp-qap/. It was developed with the aim to provide generality of algorithmic components of ACO algorithms. It separates the general structures of ACO metaheuristics from the problem-specific domain. All standard parameters can be specified ($\alpha, \beta, \rho, m, \epsilon, etc.$) plus one can set the specific parameters ($t_{max}, t_{min}, res_{it}$ - number of iterations since last found rb-solution, $res_{bf}$ - branching factor, $res_{dist}$ - distance between global-best and iteration-worst ants, $q_0$). All these parameters are to be tuned by an external configuration software.

Algorithmic frameworks can be classified as one of these two (although their distinction is ambiguous in particular cases):
\begin{itemize}
\item Top-down - develop a fixed template-based algorithm. It is based on strictly structured algorithm which allows some parametric configuration of some of its details with minor behavior modifications.
\item Bottom-up - algorithm is build of flexible components with some rule restrictions. Often involves application of genetic programming and evolution ideas.
\end{itemize}

ACOTSPQAP can be classified as the first one, since its stages (solution generation, local search, pheromone trail update) are concretely defined and its parameters are strongly determined.

\subsection{Other frameworks}

The \textbf{MOACO} framework was briefly described in the section 4. Besides there are some other optimization frameworks which have different features.

Another remarkable framework is \textbf{SATenstein}. It is based on solving satisfiability problem (SAT) of a boolean formula. SAT problem is considered important because other NP-complete problems can be encoded as instances of SAT problem. Various Stochastic Local Search (SLS) algorithms have been developed for solving SAT problems. The SATenstein can be configured to instantiate a broad range of existing high-performance SLS-based solvers \cite{satenstein}. The general form of SLS algorithm is made of five blocks. First block performs search diversification. Blocks from the second to the fourth perform a variable flip with instantiating $G^2$WSAT-derived, WalkSAT-based or dynamic local search algorithm respectively. The fifth block performs updates to the promising variable list, tabu attributes, clause penalties or dynamically adapted algorithm parameters. Thus, a high-performing SLS algorithm can be assembled of such algorithmic blocks in SATenstein. A generic algorithmic configuration tool was applied to SATenstein for finding best algorithm instantiations for predefined sets, which is described in the mentioned paper.

\textbf{Hybrid Stochastic Local Search} (SLS) algorithms, as in the previously mentioned frameworks, are composed of the separate algorithmic components. These algorithms rely on the manipulating a single solution called \emph{current solution}. The neighborhood of the current solution will be explored during the algorithm run \cite{hsls}. The first phase of the algorithm is the local search for the initial solution. Then the algorithm iterations start. One iteration consists from \emph{perturbation, local search} and \emph{acceptanceCriterion}. Perturbation is a transformation of the input solution. Perturbation may be implemented as one simple move in neighborhood space, but it may also be composed of $k$ applications of such moves. \emph{Local search} can range from a simple iterative improvement over short runs of an SA algorithm to a full-fledged iterated local search. \emph{Acceptance criterion} returns either the initial solution or the obtained one, according to some condition. The simplest criterion is \emph{improveAccept} accepts the solution with better quality. Other acceptance criteria allow worse solutions to be accepted in order to increase the exploration of the search space. For instance \emph{probAccept} accepts a worsening solution with probability $p \in [0;1]$. These iterations are repeated until a defined termination criterion is fulfilled. As a result, such metaheuristic algorithms are among the most effective non-exact algorithms for tackling hard combinatorial optimization problems.


\section{Automatic configuration in IRACE}

Automatic configuration is a process that optimizes the performance of a certain algorithm as a goal function based on input parameters of the algorithm. The general parameter types are:
 
\begin{itemize}
\item \textbf{categorical} parameters - represent discrete values without any implicit order or distance measure between its possible values. Define the choice of constructive procedure, choice of branching strategies (i. e. algorithmic blocs) and so on.
\item \textbf{ordinal} parameters - are also assigned to finite discrete values, but they have implicit value order (such as \emph{low, middle, high}). Define lower bounds, neighborhoods.
\item \textbf{numerical} parameters - define integer or real values/constants such as weighting factors, population sizes.
\end{itemize}

Some of the parameters maybe subordinate to other ones. This means that their values only make sense if the parameters, that they subordinate to, are assigned to certain values. This can be expressed as a scalar value constraint (e.g $a < b$) or as a dependency on concrete values of some categorical or ordinal parameter.

\begin{figure}[H]
  \centering
    \includegraphics[scale=0.7]{configuration-top-level.png}
  \caption{Automatic configuration scheme}
  \label{fig:autoconf}
\end{figure}

Figure \ref{fig:autoconf} shows the configuration software and software to configure. Configuration script has parameter metadata at its disposal. Based on them, the configuration software runs the software to configure with candidate configurations according to some algorithm. After the configuration process finishes, the configuration software renders the best configurations obtained. In the most general software case there are two measures of the performance - solution quality (to maximize) and computation time (to minimize). This general approach is called an offline tuning. It introduces a learning stage on training instances before learning on the real-world instance set.


A widely used configuration algorithmic family is racing algorithms. The simplified algorithm is shown in \ref{lst:racing} and an illustration is in \ref{fig:irace}.


\begin{minipage}[c, breaklines=true]{0.95\textwidth}
\begin{lstlisting}[caption={General racing pseudo-code}, label={lst:racing}]
procedure racing
start with an initial candidate set Theta
repeat iterations I
	process an instance stream
	evaluate the candidates sequentially
	remove inferior candidates
until winner is selected or exit condition fulfilled
end
\end{lstlisting}
\end{minipage}

\begin{figure}[H]
  \centering
    \includegraphics[scale=1.2]{irace.jpg}
  \caption{I-RACE execution illustration}
  \label{fig:irace}
\end{figure}


I-RACE (iterated race) configuration implementation was developed and described in \cite{iraceaac}. It was implemented in R with taking into account the parallel programming techniques and an initial candidate set-up. The feature of the IRACE is based on iterated generation of new configurations and removing of solutions with lower quality for further evaluating on the problem instances.

In order to tune the configurations that are sampled, IRACE algorithms uses independent sampling distributions for each of the parameters. For numeric values those are normal distributions and discretely-defined distributions for the rest. The configuration biasing procedure is based on modifying the sampling distributions.

Iterated racing is an automatic configuration implementation that consists of three steps:

\begin{itemize}
\item Sampling new configurations according to a particular distribution.
\item Selecting the best configurations from the newly sampled ones by means of racing.
\item Updating the sampling distribution in order to bias the sampling towards the best configurations.
\end{itemize}

After new configurations are sampled comes the selection stage. At the configuration selection stage, IRACE runs each of the configurations on a single problem instance from the predefined instance set. After each racing iteration the worst configurations are discarded. Then the rest of the configurations update parameter sampling distributions. The racing stops when the number of the survived configurations becomes small enough (defined by termination criteria).

Some IRACE extensions can be applied. \textbf{Initial configurations} can be set before the run of the IRACE. \textbf{Soft-restart} is used for preventing premature convergence. Such convergence may suppresses configuration diversity and, therefore some good configurations may be lost. This restart is triggered if the value of an ad hoc function of configuration distance is lower than a certain margin. Then reinitialization is applied to the elite configurations.


\section{Research state}

The mentioned ACOTSPQAP framework accompanied by IRACE R script have already produced results for the TSP and the QAP problems. The results are described in the following two subsections. General conclusion during this research is that solutions obtained by the optimal configurations are better than those obtained by the default configurations. The comparison was carried out by measuring the deviation from the optimal solution for each instance.

In cases where MMAS is used, user can specify the frequency of using restart-best solutions, instead of iteration-best.

\subsection{Finding a better ACO configuration for the TSP}

The optimal configuration is mentioned in the table \ref{table:table-tsp}, where it was computed for different algorithms. Various instances of different sizes were generated for the configuration process. This ACO algorithms include using of heuristic information, candidate lists and multiple types of local search.

\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}
{
\begin{tabular}{|r|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline 
    algo & $m$ & $\alpha$ & $\beta$ & $\rho$ & $q_0$ & $\epsilon$ & $cl$ & $nnls$ & $ph-limits$ & $slen$ & $restart$ & $res_{it}$\\ \hline
    ACS & 28 & 3.07 & 5.09 & 0.32 & 0.53 & 0.21 & 22 & 9 & - & - & branch-factor ($res_{bf} = 1.74$) & 212\\ \hline
	MMAS & 40 & 0.94 & 4.11 & 0.72 & 0.14 & - & 18 & 12 & yes & 191 & branch-factor ($res_{bf} = 1.91$) & 367\\ \hline
\end{tabular}
}
\caption{Optimal configuration for the TSP problem.}
\label{table:table-tsp} 
\end{table} 

With local search as 3-opt + dlb-bits.

\subsection{Finding a better ACO configuration for the QAP}

ACO algorithms do not include heuristic information, nor candidate lists, since these techniques did not prove to be useful for the QAP. Problem instances were implemented in two forms - as RR or RS. In RR the distance matrix is computed as paired euclidean distances of points distributed on a square of length 300 in uniform way. The flow matrix is generated as a matrix of uniform random values within certain range. The RS distance matrix is generated in the same way, but the flow matrix adheres to real-world flow values.

100 instances were considered where half of them was used for training and the another half for testing. The best found configuration are shown in the table \ref{table:table-qap}.

\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}
{
\begin{tabular}{|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline 
    & algo & $m$ & $\alpha$ & $\rho$ & $q_0$ & $dlb-bits$ & $ph-limits$ & $slen$ & $restart$ & $res_{it}$\\ \hline
    RR & MMAS & 6 & 0.324 & 0.29 & 0.062 & yes & no & 153 & distance ($res_{bf} = 0.051$) & 22\\ \hline
	RS & MMAS & 4 & 0.164 & 0.342 & 0.284 & yes & no & 170 & branch-factor ($res_{bf} = 1.822$) & 40\\ \hline
\end{tabular}
}
\caption{Optimal configuration for the TSP problem.}
\label{table:table-qap} 
\end{table} 

With local search as 2-best-opt.

\section{Conclusions}

Vast research work has been already conducted in terms of ACO algorithms. Many types of ACO algorithms have already been developed and tested. In addition, various technical details can be added in order to improve resolution performance or the development experience. 

Various ways of further research in this area can be proposed. The possible contribution is to implement algorithms for some other NP-hard problems in terms of ACO metaheuristic. Those can be such problems as Vehicle Routing Problem, Subset Sum Problem or Knapsack Problem.

From a technical point of view we can propose implementing a new framework using object-oriented paradigm, which will ensure high modularity and modification-proneness. Another option is to implement the ACO algorithm stages as parallel algorithms (stages like solution generation or local search). 




\begin{thebibliography}{1}

\bibitem{aco_overview} Manuel L{\'o}pez-Ib{\'a}{\~n}ez and Thomas St{\"u}tzle (2015) Ant Colony Optimization: A Component-Wise Overview.  IRIDIA - Technical Report Series.

\bibitem{comb_opt} Papadimitriou CH, Steiglitz K (1982) Combinatorial Optimization – Algorithms and Complexity. Prentice Hall, Englewood Cliffs, NJ

\bibitem{maniezzo} Maniezzo V (1999) Exact and approximate nondeterministic tree-search procedures for the quadratic assignment problem. INFORMS Journal on Computing 11(4):358-369

\bibitem{dorigo} Dorigo M, Gambardella LM (1997) Ant Colony System: A cooperative learning approach to the traveling salesman problem. IEEE Transactions on Evolutionary Computation 1(1):53-66

\bibitem{lookahead} Michel R, Middendorf M (1998) An island model based Ant System with lookahead for the shortest supersequence problem. In: Eiben AE, Bäck T, Schoenauer M, Schwefel HP (eds) Parallel Problem Solving from Nature, PPSN V, Lecture Notes in Computer Science, vol 1498, Springer, Heidelberg, Germany, pp 692-701

\bibitem{lookahead2} C. Gagne, M. Gravel, and W. Price (2001) A look-ahead addition to the ant colony optimization metaheuristic and its application to an industrial scheduling problem: in Proceedings of the 4th Metaheuristics International Conference (MIC ’01), J. Sousa, Ed., pp. 79-84, Porto, Portugal

\bibitem{candidate_list} Dorigo M, Di Caro GA (1999) The Ant Colony Optimization meta-heuristic. In: Corne D, Dorigo M, Glover F (eds) New Ideas in Optimization, McGraw Hill, London, UK, pp 11-32

\bibitem{hash_table} Alba E, Chicano F (2007) ACOhg: dealing with huge graphs. In: Thierens D, et al (eds) Proceedings of the Genetic and Evolutionary Computation Conference, GECCO 2007, ACM Press, New York, NY, pp 10-17

\bibitem{iterated_greedy} Ruiz R, Thomas St{\"u}tzle (2007) A simple and effective iterated greedy algorithm for the permutation flowshop scheduling problem. European Journal of Operational Research 177(3):2033-2049

\bibitem{iterated_ants} Wiesemann W, St{\"u}tzle T (2006) Iterated ants: An experimental study for the quadratic assignment problem. In: Dorigo M, et al (eds) Ant Colony Optimization and Swarm Intelligence, 5th International Workshop, ANTS 2006, Lecture Notes in Computer Science, vol 4150, Springer, Heidelberg, Germany, pp 179-190

\bibitem{cunning_ants} Tsutsui S (2007) Ant colony optimization with cunning ants. Transactions of the Japanese Society for Artificial Intelligence 22:29-36

\bibitem{mmas} Thomas St{\"u}tzle and Hoos HH Stützle T, Hoos HH (2000) MAX–MIN Ant System. Future Generation Computer Systems 16(8):889-914

\bibitem{ras} Bullnheimer B, Hartl R, Strauss C (1999) A new rank-based version of the Ant System: A computational study. Central European Journal for Operations Research and Economics 7(1):25-38

\bibitem{eas} Dorigo M (1992) Optimization, learning and natural algorithms. PhD thesis, Dipartimento di Elettronica, Politecnico di Milano, Italy, in Italian

\bibitem{bwas} Cord{\'o}n O, de Viana IF, Herrera F, Moreno L (2000) A new ACO model integrating evolutionary computation concepts: The best-worst ant system. In: Dorigo M, et al (eds) Abstract proceedings of ANTS 2000 – From Ant Colonies to Artificial Ants: Second International Workshop on Ant Algorithms, IRIDIA, Universit{\'e} Libre de Bruxelles, Belgium, pp 22-29

\bibitem{coop_tsp} Dorigo M, Gambardella LM (1997) Ant Colony System: A cooperative learning approach to the traveling salesman problem. IEEE Transactions on Evolutionary Computation 1(1):53-66

\bibitem{iraceaac} Manuel L{\'o}pez-Ib{\'a}{\~n}ez and J{\'e}r{\'e}mie Dubois-Lacoste and Leslie {P{\'e}rez C{\'a}ceres} and Thomas St{\"u}tzle  and  Mauro Birattari (2013) Iterated Racing for Automatic Algorithm Configuration. IRIDIA - Technical Report Series, vol 3, Operations Research Perspectives, pp 43-58.

\bibitem{aco_continuous} Socha K, Dorigo M (2008) Ant colony optimization for continuous domains. European Journal of Operational Research 185(3):1155-1173
  
\bibitem{aco_incremental} Liao T, Montes de Oca MA, Aydin D, St{\"u}tzle T, Dorigo M (2011) An incremental ant colony algorithm with local search for continuous optimization. In: Krasnogor N, Lanzi PL (eds) Proceedings of the Genetic and Evolutionary Computation Conference, GECCO 2011, ACM Press, New York, NY, pp 125-132
  
\bibitem{moaco} L{\'o}pez-Ib{\'a}{\~n}ez M, St{\"u}tzle T (2012) The automatic design of multi-objective ant colony optimization algorithms. IEEE Transactions on Evolutionary Computation 16(6):861-875

\bibitem{dynamic_overview} Leguizam{\'o}n G, Alba E (2013) Ant colony based algorithms for dynamic optimization problems. In: Alba E, Nakib A, Siarry P (eds) Metaheuristics for Dynamic Optimization, Studies in Computational Intelligence, vol 433, Springer, Berlin/Heidelberg, pp 189-210
 
\bibitem{bianchi_stochastic_tsp} Bianchi L, Gambardella LM, Dorigo M (2002) An ant colony optimization approach to the probabilistic traveling salesman problem. In: Merelo JJ, et al (eds) Parallel Problem Solving from Nature, PPSN VII, Springer, Heidelberg, Germany, Lecture Notes in Computer Science, vol 2439, pp 883-892

\bibitem{guntsch_stochastic} Guntsch M, Branke J (2003) New ideas for applying ant colony optimization to the probabilistic tsp. In: Cagnoni S, et al (eds) Applications of Evolutionary Computing, Proceedings of EvoWorkshops 2003, Springer, Heidelberg, Germany, Lecture Notes in Computer Science, vol 2611, pp 165-175

\bibitem{hsls} Marie-El´eonore Marmion, Franco Mascia, Manuel L{\'o}pez-Ib{\'a}{\~n}ez, and Thomas St{\"u}tzle (2013) IRIDIA, CoDE, Universit{\'e} Libre de Bruxelles (ULB), Brussels, Belgium, pp 144-158

\bibitem{satenstein} R. KhudaBukhsh, L. Xu, H. H. Hoos, K. Leyton-Brown (2009) SATenstein: Automatically Building Local Search SAT Solvers From Components, Twenty-First International Joint Conference on Artificial Intelligence (IJCAI-09)

\bibitem{external_memory} Acan A (2004) An external memory implementation in ant colony optimization. In: Dorigo M, et al (eds) Ant Colony Optimization and Swarm Intelligence, 4th International Workshop, ANTS 2004, Lecture Notes in Computer Science, vol 3172, Springer, Heidelberg, Germany, pp 73-84

\end{thebibliography}

 
\end{document} 
