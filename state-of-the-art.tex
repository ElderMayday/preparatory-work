\documentclass[12pt]{article}
\usepackage{caption}
\usepackage{float}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage{tabto}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{tabularx}

\lstset{
    frame=single,
    breaklines=true,
    postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\color{red}\hookrightarrow\space}}
}

\graphicspath{{images/}}

\author{Aldar Saranov}
\date{\today}
\title{Development of an automatically configurable ant colony optimization framework. State of the art.}

\newmdenv[
  backgroundcolor=gray!20,
  frametitle=Definition,
  skipabove=\topsep,
  skipbelow=\topsep,
]{definition}

\newmdenv[
  backgroundcolor=white!20,
  frametitle=Algorithm,
  skipabove=\topsep,
  skipbelow=\topsep,
]{algorithm}

\newcommand{\dd}[1]{\mathrm{d}#1}


%--------------------------------------------------------------------------------



\begin{document}

\maketitle 
\newpage

\tableofcontents
\newpage

\begin{abstract}
Some animal species show an extreme degree of social organization. Such species (e.g. ants) have pheromone production and detection body parts and therefore seize an ability to communicate between each other in indirect way. This concept has inspired the development of algorithms which are based on social behavior of ant colony called ant colony optimization algorithms. These algorithms allow to solve NP-hard problems in a very efficient manner. Since these algorithms are considered to be metaheuristics the development of an ACO framework is the next step of formalizing of this area is to provide tools for resolving general optimization problems. This article gives a brief overview of the current state of the ACO research area, existing framework description and some tools which can be used for the automatic configuration of the framework.
\end{abstract}




\section{Introduction (1 page)}
Section descriptions.
Pheromones.
Constructive heuristics.
Solution components.
Problem models.

\input{section-2}
\input{section-3}
\input{section-4}





\section{Existing ACO framework (5 pages)}

ACOTSP unified framework was developed by IRIDIA group. It was developed with tendency towards the purpose and component generality. It separates the general structures of ACO metaheuristics from the problem-specific domain. All standard parameters can be specified ($\alpha, \beta, \rho, m, \epsilon, etc.$) plus one can set the specific parameters ($t_{max}, t_{min}, res_{it}$ - number of iterations since last found rb-solution, $res_{bf}$ - branching factor, $res_{dist}$ - distance between global-best and iteration-worst ants, $q_0$).

+ MOACO, MOBA, Saternstein, hybridSLS ~1-2 parag!!!



\section{Automatic configuration in IRACE (3 pages)}

Automatic configuration is a process that optimizes the performance of a certain algorithm as a goal function based on input parameters of the algorithm. The general parameter types are:
 
\begin{itemize}
\item \textbf{categorical} parameters - define the choice of constructive procedure, choice of branching strategies (i. e. algorithmic blocs) and so on.
\item \textbf{ordinal} parameters - define lower bounds, neighborhoods.
\item \textbf{numerical} parameters - define integer or real values/constants such as weighting factors, population sizes, temperature. They can be optional according to different categorical parameter values.
\end{itemize}

\begin{figure}[H]
  \centering
    \includegraphics[scale=0.7]{configuration-top-level.png}
  \caption{Automatic configuration scheme}
  \label{fig:autoconf}
\end{figure}

Figure \ref{fig:autoconf} shows software composition of the analyzed program and configuration script. Configuration script has parameter metadata in its disposal. Based on them, the configuration software runs the software to configure with candidate configurations one by one according to the higher-mentioned racing algorithm. The result of the run is the solution cost of cumulative runs of the algorithm on the defined problem instances. After the racing process finishes, the configuration software renders the best configuration obtained. In the most general software case there are two measures of the performance - solution quality (to maximize) and computation time (to minimize).

There are two application modes:
\begin{itemize}
\item Offline tuning - introduces a learning stage on training instances before learning on the actual set.
\item Online tuning - tunes the parameters while solving the actual instance set.
\end{itemize}

A widely used configuration algorithmic family is racing algorithms. The simplified algorithm is shown in \ref{lst:racing} and an illustration is showed in \ref{fig:irace}.


\begin{minipage}[c, breaklines=true]{0.95\textwidth}
\begin{lstlisting}[caption={General racing pseudo-code}, label={lst:racing}]
procedure racing
start with an initial candidate set Theta
repeat iterations I
	process an instance stream
	evaluate the candidates sequentially
	remove inferior candidates
until winner is selected or exit condition fulfilled
end
\end{lstlisting}
\end{minipage}

\begin{figure}[H]
  \centering
    \includegraphics[scale=1.2]{irace.jpg}
  \caption{I-RACE execution illustration}
  \label{fig:irace}
\end{figure}


I-RACE(iterated race) implementation has already been developed and applied for the ACO problem in \cite{iraceaac}. It was implemented in R with taking into account the parallel programming techniques and initial candidate set-up. The feature of the IRACE is based on iterated generation of new configurations and removing of solutions with less fitness for further evaluating on the problem instances.


Two conceptual approaches can be remarked (although their distinction is ambiguous in particular cases):
\begin{itemize}
\item Top-down - develop a fixed template-based algorithm. It is based on strictly structured algorithm which allows some parametric configuration of some of its details with minor behavior modifications.
\item Bottom-up - algorithm is build of flexible components with some rule restrictions. Often involves application of genetic programming and evolution ideas.
\end{itemize}

\section{Research state}

The higher-mentioned ACOTSP framework accompanied by IRACE R script have already produced results for the TSP and the QAP problems. The results are described in the following two subsections. General conclusion during this research is that solutions obtained by the optimal configurations are better than those obtained by the default configurations. The comparison was carried out by measuring the deviation from the optimal solution for each instance.

\subsection{Finding a better ACO configuration for the TSP}

The optimal configuration is mentioned in the table \ref{table:table-tsp}, where it was computed for different algorithms. Various instances of different sizes were generated for the configuration process.

\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}
{
\begin{tabular}{|r|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline 
    algo & $m$ & $\alpha$ & $\beta$ & $\rho$ & $q_0$ & $\epsilon$ & $cl$ & $nnls$ & $ph-limits$ & $slen$ & $restart$ & $res_{it}$\\ \hline
    ACS & 28 & 3.07 & 5.09 & 0.32 & 0.53 & 0.21 & 22 & 9 & - & - & branch-factor ($res_{bf} = 1.74$) & 212\\ \hline
	MMAS & 40 & 0.94 & 4.11 & 0.72 & 0.14 & - & 18 & 12 & yes & 191 & branch-factor ($res_{bf} = 1.91$) & 367\\ \hline
\end{tabular}
}
\caption{Optimal configuration for the TSP problem.}
\label{table:table-tsp} 
\end{table} 

With local search as 3-opt + dlb-bits.

\subsection{Finding a better ACO configuration for the QAP}

Problem instances were implemented in two forms - as RR or RS. In RR the distance matrix is computed as paired euclidean distances of points distributed on a square of length 300 in uniform way. The flow matrix is generated as a matrix of uniform random values within certain range. The RS distance matrix is generated in the same way, but the flow matrix adheres to real-world flow values.

100 instances were considered where half of them was used for training and the another half for testing. The best found configuration are shown in the table \ref{table:table-qap}.

\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}
{
\begin{tabular}{|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline 
    & algo & $m$ & $\alpha$ & $\rho$ & $q_0$ & $dlb-bits$ & $ph-limits$ & $slen$ & $restart$ & $res_{it}$\\ \hline
    RR & MMAS & 6 & 0.324 & 0.29 & 0.062 & yes & no & 153 & distance ($res_{bf} = 0.051$) & 22\\ \hline
	RS & MMAS & 4 & 0.164 & 0.342 & 0.284 & yes & no & 170 & branch-factor ($res_{bf} = 1.822$) & 40\\ \hline
\end{tabular}
}
\caption{Optimal configuration for the TSP problem.}
\label{table:table-qap} 
\end{table} 

With local search as 2-best-opt.

\section{Conclusions}


\subsection{Possible improvements}



\begin{thebibliography}{1}


\bibitem{iraceaac} Manuel L{\'o}pez-Ib{\'a}{\~n}ez  and  J{\'e}r{\'e}mie Dubois-Lacoste  and Leslie {P{\'e}rez C{\'a}ceres}  and  Thomas St{\"u}tzle  and  Mauro Birattari {\em Iterated Racing for Automatic Algorithm Configuration} 2013: IRIDIA - Technical Report Series.
  
\bibitem{external_memory} Dorigo, Marco
and Birattari, Mauro
and Blum, Christian
and Gambardella, Luca Maria
and Mondada, Francesco
and St{\"u}tzle, Thomas {\em IAn External Memory Implementation in Ant Colony Optimization} 2004: Springer Berlin Heidelberg - Proceedings.

\end{thebibliography}


\end{document} 
